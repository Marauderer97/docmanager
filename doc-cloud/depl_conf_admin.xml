<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter 
[
 <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.depl.adm_conf">
 <info>
  <title>Configuring the &admserv;</title>
  <abstract>
   <para>
    After the installation of the operating system and the add-on products
    on the &admserv; has finished, you need to set up product and update
    repositories and, optionally, configure a custom network setup. After
    the &admserv; host is fully configured, start the cloud installation
    script.
   </para>
  </abstract>
 </info>
 <sect1 xml:id="sec.depl.adm_conf.repos">
  <title>Setting up the Repositories</title>

  <para>
   Nodes in &cloud; are automatically installed from the &admserv;. To
   do so, software repositories containing products, extensions and the
   respective updates for all software need to be available on or accessible
   from the &admserv;. Two types of repositories can be distinguished:
  </para>

  <variablelist>
   <varlistentry>
    <term>Product Media Repositories</term>
    <listitem>
     <para>
      Product media repositories are copies of the installation media. They
      need to be directly copied to the &admserv;,
      <quote>loop-mounted</quote> from an iso image or mounted from a remote
      server via NFS. Affected are &slsa; 11 SP3 (DVD #1),
      &productname; &productnumber; (DVD #1), and, optionally,
      &slsa; 12 (DVD #1). The first two are mandatory, the latter is only
      needed when wanting to set up &compnode;s running &slsa; 12 or
      &ceph; &stornode;s. The content of these repositories is static.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Update and Pool Repositories</term>
    <listitem>
     <para>
      Update and Pool repositories are provided by the &scc;. They
      provide all updates and patches for the products and extensions. To
      make them available for &cloud; they need to be mirrored from the
      &scc;. Since their content is regularly updated, they need to be
      kept in synchronization with &scc;. For these purposes, &suse;
      provides either the &smtool; (&smt;) or the &susemgr;.
     </para>
     <para>
      The repositories can be made available on the &admserv; using one
      of the following methods (or a mix of them):
     </para>
     <itemizedlist mark="bullet" spacing="normal">
      <listitem>
       <para>
        <xref linkend="sec.depl.adm_conf.repos.scc.local_smt"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <xref linkend="sec.depl.adm_conf.repos.scc.remote_smt"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <xref linkend="sec.depl.adm_conf.repos.scc.remote_susemgr"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <xref linkend="sec.depl.adm_conf.repos.scc.remote"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <xref linkend="sec.depl.adm_conf.repos.scc.sneaker"/>
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
  </variablelist>

  <sect2 xml:id="sec.depl.adm_conf.repos.product">
   <title>Copying the Product Media Repositories</title>
   <para>
    The files in the product repositories for &sls; and &cloud; do not
    change, therefore they do not need to be synchronized with a remote
    source. It is sufficient to either copy the data (from a remote host or
    the installation media) or mount the product repository from a remote
    server via <literal>NFS</literal>. Alternatively you may copy the iso
    images of DVD #1 from the products to the &admserv; and <quote>loop
    mount</quote> them. Refer to
    <xref linkend="sec.depl.adm_conf.repos.product"/> for instructions.
   </para>
   <important>
    <title>No Symbolic Links for the &sls; Repository</title>
    <para>
     Note that the &sls; product repository <emphasis>must</emphasis> be
     directly available from the local directory listed below. It is not
     possible to use a symbolic link to a directory located elsewhere, since
     this will cause booting using PXE to fail.
    </para>
   </important>
   <tip>
    <title>Providing the &productname; Repository via HTTP</title>
    <para>
     While the &sls; product repositories needs to be made available
     locally to enable PXE boot for node deployment, the &productname;
     repository may also be served via <literal>http</literal> from a remote
     host. In this case, enter the URL to the <literal>Cloud</literal>
     repository as described in
     <xref linkend="sec.depl.adm_inst.crowbar.repos"/>.
    </para>
    <para>
     However, copying the data to the &admserv; as described here, is
     recommended. It does not require much hard disk space ((approximately
     &mediaspace;) nor does it require the &admserv; to be able to
     access a remote host from a different network.
    </para>
   </tip>
   <para>
    The following product media needs to be copied to the specified
    directories:
   </para>
   <table>
    <title>Local Product Repositories for &cloud;</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="40*"/>
     <colspec colnum="2" colname="2" colwidth="60*"/>
     <thead>
      <row>
       <entry>
        <para>
         Repository
        </para>
       </entry>
       <entry>
        <para>
         Directory
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         &slsa; 11 SP3 DVD #1
        </para>
       </entry>
       <entry>
        <para>
         <filename>/srv/tftpboot/suse-11.3/install/</filename>
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         &productname; &productnumber; DVD #1 (Cloud for &slsa; 11
         SP3)
        </para>
       </entry>
       <entry>
        <para>
         <filename>/srv/tftpboot/suse-11.3/repos/Cloud/</filename>
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         &slsa; 12 DVD #1 (optional)
        </para>
       </entry>
       <entry>
        <para>
         <filename>/srv/tftpboot/suse-12.0/install/</filename>
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         &productname; &productnumber; DVD #4 (optional, Cloud for
         &slsa; 12)
        </para>
       </entry>
       <entry>
        <para>
         <filename>/srv/tftpboot/suse-12.0/repos/Cloud/</filename>
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <para>
    The data can be copied by a variety of methods:
   </para>
   <sect3 xml:id="sec.depl.adm_conf.repos.product.media">
    <title>Copying from the Installation Media</title>
    <para>
     If copying, it is recommended to use <command>rsync</command>. If the
     installation data is located on a removable device, make sure to mount
     it first (for example, after inserting the DVD1 in the &admserv; and
     waiting for the device to become ready):
    </para>
    <variablelist>
     <varlistentry>
      <term>&slsa; 11 SP3 DVD #1</term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-11.3/install/
umount /mnt</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-11.3/repos/Cloud/
umount /mnt</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>&slsa; 12 DVD #1</term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-12.0/install/
umount /mnt</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount /dev/dvd /mnt
rsync -avP /mnt/ /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
umount /mnt</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.product.remote">
    <title>Copying from a Remote Host</title>
    <para>
     If the data is provided by a remote machine, log in to that machine and
     push the data to the &admserv; (which has the IP address
     <systemitem class="etheraddress">192.168.124.10</systemitem> in the
     following example):
    </para>
    <variablelist>
     <varlistentry>
      <term>&slsa; 11 SP3 DVD #1</term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
rsync -avPz <replaceable>/data/SLES-11-SP3/DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/install/</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
rsync -avPz <replaceable>/data/SUSE-CLOUD//DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/repos/Cloud/</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>&slsa; 12 DVD #1</term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
rsync -avPz <replaceable>/data/SLES-12//DVD1/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-12.0/install/</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
rsync -avPz <replaceable>/data/SUSE-CLOUD//DVD4/</replaceable> <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.product.nfs">
    <title>Mounting from an NFS Server</title>
    <para>
     If the installation data is provided via NFS by a remote machine, mount
     the respective shares as follows. To automatically mount these
     directories either create entries in <filename>/etc/fstab</filename> or
     set up the automounter.
    </para>
    <variablelist>
     <varlistentry>
      <term>&slsa; 11 SP3 DVD #1</term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SLES-11-SP3/x86_64/DVD1/</replaceable> /srv/tftpboot/suse-11.3/install</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD1/</replaceable> /srv/tftpboot/suse-11.3/repos/Cloud</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>&slsa; 12 DVD #1</term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SLES-12/x86_64/DVD1/</replaceable> /srv/tftpboot/suse-12.0/install</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD4/</replaceable> /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute
umount /mnt</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.product.loop">
    <title>Mounting ISO Images</title>
    <para>
     he product repositories can also be made available by copying the
     respective iso images to the &admserv; and mounting them. To
     automatically mount these directories either create entries in
     <filename>/etc/fstab</filename> or set up the automounter.
    </para>
    <variablelist>
     <varlistentry>
      <term>&slsa; 11 SP3 DVD #1</term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/install/
mount -o loop <replaceable>/local/SLES-11-SP3-x86_64-DVD1.iso</replaceable> /srv/tftpboot/suse-11.3/install/</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #1 (Cloud for &slsa; 11 SP3)
       </term>
      <listitem>
<screen>mkdir -p /srv/tftpboot/suse-11.3/repos/Cloud/
mount -o loop <replaceable>/local/SUSE-CLOUD-&productnumber;-DVD1.iso</replaceable> /srv/tftpboot/suse-11.3/repos/Cloud</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>&slsa; 12 DVD #1</term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/install/
mount -o loop <replaceable>/local/SLES-12-x86_64-DVD1.iso</replaceable> /srv/tftpboot/suse-12.0/install</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
	&productname; &productnumber; DVD #4 (Cloud for &slsa; 12)
       </term>
      <listitem>
       <para>
        Note that this repository only needs to be copied in case you want
        to deploy &slsa; 12 &compnode;s or &ceph; &stornode;s.
       </para>
<screen>mkdir -p /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute/
mount -t nfs <replaceable>nfs.&exampledomain;:/exports/SUSE-CLOUD/DVD4/</replaceable> /srv/tftpboot/suse-12.0/repos/SLE12-Cloud-Compute</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.depl.adm_conf.repos.scc">
   <title>Update and Pool Repositories</title>
   <para>
    Update repositories are already used when deploying the nodes that will
    build &cloud; to ensure they are initially equipped with the latest
    software versions available. If you have installed an &smt; server on
    the &admserv;, no further action is required, all repositories will
    automatically be detected. If you are using a remote &smt; or SUSE
    Manager server, the update repositories from the remote server are used
    directly. In this case the repository URLs need to be added via the
    &yast; Crowbar module as explained in
    <xref linkend="sec.depl.adm_inst.crowbar.repos"/>. If using repositories
    locally available, the &admserv; itself acts as the repository
    provider for all nodes. This requires to make them available in
    <filename>/srv/tftpboot/suse-11.3/repos</filename>.
   </para>
   <sect3 xml:id="sec.depl.adm_conf.repos.scc.local_smt">
    <title>Repositories Hosted on an &smt; Server Installed on the &admserv;</title>
    <para>
     When all update and pool repositories are managed by an &smt; server
     installed on the &admserv; (see <xref linkend="app.deploy.smt"/>) no
     further action is required. The &cloud; installation script
     automatically detects all required repositories and creates links to
     them in <filename>/srv/tftpboot/suse-11.3/repos</filename> and
     <filename>/srv/tftpboot/suse-12.0/repos</filename>.
    </para>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.scc.remote_smt">
    <title>Repositories Hosted on a Remote &smt; Server</title>
    <para>
     To use repositories from a remote &smt; server you first need to
     make sure all required repositories are mirrored on the server. Refer
     to <xref linkend="app.deploy.smt.repos"/> for more information. Now you
     need to enter the repository URLs on the
     <guimenu>Repositories</guimenu> tab in the &yast; &crow; module
     as described in <xref linkend="sec.depl.adm_inst.crowbar.repos"/>. A
     complete set of repository URLs is listed at
     <xref linkend="tab.smt.repos"/>. Note that you need to replace
     <replaceable>smt.&exampledomain;</replaceable> with the fully
     qualified host name of your &smt; server.
    </para>
    <note>
     <title>Accessing an External &smt; Server</title>
     <para>
      In &cloud;, only the &admserv; needs to be able to access the
      external &smt; server. A network connection can either be
      established via a bastion network (see
      <xref linkend="sec.depl.adm_inst.crowbar.mode.bastion"/> or an
      external gateway.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.scc.remote_susemgr">
    <title>Repositories Hosted on a &susemgr; Server</title>
    <para>
     To use repositories from &susemgr; you first need to make sure all
     required products and extensions are registered and the corresponding
     channels are mirrored in &susemgr; (refer to
     <xref linkend="tab.depl.adm_conf.susemgr-repos"/> for a list of
     channels).
    </para>
    <important>
     <title>Accessing a &susemgr; Server</title>
     <para>
      An external &susemgr; server needs to be accessed from
      <emphasis>all</emphasis> nodes in &cloud;. To be able to access it,
      the network hosting the &susemgr; server needs to be added to the
      network definitions as described in
      <xref linkend="sec.depl.inst.admserv.post.network.external"/>.
     </para>
    </important>
    <para>
     By default &susemgr; does not expose repositories for direct access.
     To be able to access them via <literal>https</literal>, you need to
     create a <guimenu>Distribution</guimenu> for auto-installation for the
     &sls; 11 SP3 (x86_64) product on &susemgr;. If you plan to also
     deploy &slsa; 12 &compnode;s or &ceph; &stornode;s, you
     also need to do this for the &sls; 12 (x86_64) Product. Instructions
     can be found at
     <link xlink:href="https://www.suse.com/documentation/suse_manager/book_susemanager_ref/data/book_susemanager_ref.html"/>
     under the heading <guimenu>Creating Distribution for
     Autoinstallation</guimenu>.
    </para>
    <para>
     During the distribution setup you need to provide a
     <guimenu>Label</guimenu> for the distribution. This label will be part
     of the URL under which the repositories are available. It is
     recommended to choose a name consisting of characters that do not need
     to be URL-encoded, for example <literal>sles11-sp3-x86_64</literal> and
     <literal>sles12-x86_64</literal>.
    </para>
    <para>
     Creating a distribution for &slsa; not only makes the update
     repositories for this product available, but also for all registered
     add-on products, including &productname; &productnumber; and
     other extensions.
    </para>
    <para>
     To make the repositories available for node deployment, you need to
     enter the repository URLs on the <guimenu>Repositories</guimenu> tab in
     the &yast; &crow; module as described in
     <xref linkend="sec.depl.adm_inst.crowbar.repos"/>.
    </para>
    <para>
     The repositories are available under the URLs listed below.
     <literal>manager.&exampledomain;</literal> needs to be replaced by
     the fully qualified host name of your &susemgr; server.
     <literal>sles11-sp3-x86_64</literal> and
     <literal>sles12-x86_64</literal> need to be replaced by the
     distribution labels you specified when setting up the distribution for
     auto-installation. Note that the URLs are not browseable.
    </para>
    <table xml:id="tab.depl.adm_conf.susemgr-repos">
     <title>&susemgr; Channels and URLs</title>
     <tgroup cols="2">
      <colspec colnum="1" colname="1" colwidth="25*"/>
      <colspec colnum="2" colname="2" colwidth="75*"/>
      <thead>
       <row>
        <entry>
         <para>
          Channel
         </para>
        </entry>
        <entry>
         <para>
          URL
         </para>
        </entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry namest="1" nameend="2">
         <para>
          Mandatory Repositories
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES11-SP3-Updates
         </para>
        </entry>
        <entry>
         <para>
          http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sles11-sp3-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Cloud-5-Pool
         </para>
        </entry>
        <entry>
         <para>
          http://manager.&exampledomain;/ks/dist/child/suse-cloud-5-pool-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Cloud-5-Updates
         </para>
        </entry>
        <entry>
         <para>
          http://manager.&exampledomain;/ks/dist/child/suse-cloud-5-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry namest="1" nameend="2">
         <para>
          Optional Repositories
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES12-Updates
         </para>
        </entry>
        <entry>
         <para>
          http://<replaceable>manager.&exampledomain;</replaceable>ks/dist/child/sles12-updates-x86_64/<replaceable>sles12-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE-12-Cloud-Compute5-Pool
         </para>
        </entry>
        <entry>
         <para>
          to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE-12-Cloud-Compute5-Updates
         </para>
        </entry>
        <entry>
         <para>
          to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE11-HAE-SP3-Pool
         </para>
        </entry>
        <entry>
         <para>
          http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sle11-hae-sp3-pool-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE11-HAE-SP3-Updates
         </para>
        </entry>
        <entry>
         <para>
          http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/sle11-hae-sp3-updates-x86_64/<replaceable>sles11-sp3-x86_64</replaceable>/
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Enterprise-Storage-1.0-Pool
         </para>
        </entry>
        <entry>
         <para>
          to be announced
<!--
	  http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Enterprise-Storage-1.0-Updates
         </para>
        </entry>
        <entry>
         <para>
          to be announced
<!--
	 http://<replaceable>manager.&exampledomain;</replaceable>/ks/dist/child/???/<replaceable>sles12-x86_64</replaceable>/
-->
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>
    <para>
     The autoinstallation tree provided by &susemgr; does not provide the
     &slsa; Pool repositories. Although these repositories are not used
     for node installation, &ay;, which is used for the automatic
     installation, requires them to be present. To work around this issue,
     it is sufficient to create an empty Pool repository for &slsa; 11
     SP3:
    </para>
<screen>mkdir /srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/
createrepo /srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/</screen>
    <para>
     In case you plan deploy optional &slsa; 12 nodes, you also need to
     create the respective &slsa; 12 repository:
    </para>
<screen>mkdir /srv/tftpboot/suse-12.0/repos/SLES12-Pool/
createrepo /srv/tftpboot/suse-12.0/repos/SLES12-Pool/</screen>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.scc.remote">
    <title>Repositories Hosted on a Remote Host</title>
    <para>
     If the update repositories are hosted on a remote host that can be
     accessed from the &admserv; you can either mount them, for example
     via <literal>NFS</literal>, or regularly <command>rsync</command> them.
    </para>
    <para>
     To <literal>NFS</literal>-mount the repositories from a remote host,
     either use the &yast; <guimenu>NFS Client</guimenu> module or edit
     <filename>/etc/fstab</filename>. See
     <xref linkend="tab.depl.adm_conf.local-repos"/> for a table of
     repositories and their local mount points.
    </para>
    <para>
     To <command>rsync</command> the repositories from a remote host, create
     a daily cron job for mirroring. The following example pulls the
     mandatory repositories from a host named host.&exampledomain;. The
     optional repositories can be mirrored the same way. Refer to
     <xref linkend="tab.depl.adm_conf.local-repos"/> for a table of
     repositories and their local target directories.
    </para>
<screen><?dbsuse-fo font-size="0.63em"?>for REPO in SLES11-SP3-{Pool,Updates} SUSE-Cloud-5-{Pool,Updates}; do
  rsync -avPz host.&exampledomain;:/srv/www/htdocs/repo/\\\$RCE/$REPO/sle-11-x86_64/ \
  /srv/tftpboot/suse-11.3/repos/${REPO}/
done</screen>
    <para>
     Alternatively you may set up the cron job on the remote host and
     <emphasis>push</emphasis> the files to the &admserv; (which has the
     IP address <systemitem class="etheraddress">192.168.124.10</systemitem>
     in the following example):
    </para>
<screen><?dbsuse-fo font-size="0.63em"?>for REPO in SLES11-SP3-{Pool,Updates} SUSE-Cloud-5-{Pool,Updates}; do
  rsync -avPz /srv/www/htdocs/repo/\\\$RCE/$REPO/sle-11-x86_64/ \
  <replaceable>192.168.124.10</replaceable>:/srv/tftpboot/suse-11.3/repos/${REPO}/
done</screen>
    <note>
     <title>Mind the Trailing Slash</title>
     <para>
      The <command>rsync</command> command must be used with trailing
      slashes in the directory names as shown above. Otherwise rsync would
      copy the repositories into the wrong directory.
     </para>
    </note>
    <note>
     <title>Accessing a remote Host</title>
     <para>
      A remote machine hosting the update repositories needs to be accessed
      from the &admserv; only. A network connection can either be
      established via a bastion network (see
      <xref linkend="sec.depl.adm_inst.crowbar.mode.bastion"/> or an
      external gateway.
     </para>
    </note>
    <table xml:id="tab.depl.adm_conf.local-repos">
     <title>Repository Locations on the &admserv;</title>
     <tgroup cols="2">
      <colspec colnum="1" colname="1" colwidth="25*"/>
      <colspec colnum="2" colname="2" colwidth="75*"/>
      <thead>
       <row>
        <entry>
         <para>
          Channel
         </para>
        </entry>
        <entry>
         <para>
          Directory on the &admserv;
         </para>
        </entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry namest="1" nameend="2">
         <para>
          Mandatory Repositories
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES11-SP3-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SLES11-SP3-Pool/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES11-SP3-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SLES11-SP3-Updates/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Cloud-5-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SUSE-Cloud-5-Pool/</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Cloud-5-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SUSE-Cloud-5-Updates</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry namest="1" nameend="2">
         <para>
          Optional Repositories
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES12-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SLES12-Pool</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLES12-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SLES12-Updates</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE-12-Cloud-Compute5-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SLE-12-Cloud-Compute5-Pool</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE-12-Cloud-Compute5-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SLE-12-Cloud-Compute5-Updates</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE11-HAE-SP3-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SLE11-HAE-SP3-Pool</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SLE11-HAE-SP3-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-11.3/repos/SLE11-HAE-SP3-Updates</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Enterprise-Storage-1.0-Pool
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SUSE-Enterprise-Storage-1.0-Pool</filename>
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          SUSE-Enterprise-Storage-1.0-Updates
         </para>
        </entry>
        <entry>
         <para>
          <filename>/srv/tftpboot/suse-12.0/repos/SUSE-Enterprise-Storage-1.0-Updates</filename>
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>
   </sect3>
   <sect3 xml:id="sec.depl.adm_conf.repos.scc.sneaker">
    <title>Repositories Hosted on Removable Media (<quote>Sneakernet</quote>)</title>
    <para>
     If your admin network is isolated from other networks, you need to
     manually synchronize the update repositories from removable media. To
     do so you can either use <command>rsync</command> (see above for an
     example) or <command>cp</command> <option>-axu</option>. If copying
     from an &smt; server, see
     <xref linkend="tab.depl.adm_conf.local-repos"/> for a list of
     directories to copy to.
    </para>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.depl.inst.admserv.post.adm_repos">
  <title>Default Software Repository Sources on the &admserv;</title>

  <para>
   Update repositories are not only required to deploy &cloud;. The
   &admserv; itself also needs to be kept up-to-date and therefore needs
   to have a proper repository setup. In case you have registered &sls;
   and &productname; during the installation process, the &admserv;
   already has all required update repositories.
  </para>

  <para>
   These repositories are served directly from &ncc;. To avoid
   downloading the same patches twice or in case you want to cut off the
   &admserv; from the Internet, it makes sense to change this setup in a
   way that the repositories set up for &cloud; deployment are also used
   on the &admserv;. To do so, you need to disable or delete all
   services. In a second step all &sls; and &cloud; repositories need
   to be edited to point to the alternative sources. Editing the repository
   setup can either be done with Zypper or &yast;. Note that changing the
   repository setup on the &admserv; is optional.
  </para>
 </sect1>
 <sect1 xml:id="sec.depl.inst.admserv.post.network">
  <title>Custom Network Configuration</title>

  <para>
   In case you need to adjust the pre-defined network setup of &cloud;
   beyond the scope of changing IP address assignments (as described in
   <xref linkend="sec.depl.adm_inst.crowbar"/>), you need to manually modify
   the network &barcl; template. Refer to
   <xref linkend="app.deploy.network_json"/> for details.
  </para>

  <sect2 xml:id="sec.depl.inst.admserv.post.network.external">
   <title>Providing Access to External Networks</title>
   <para>
    By default, external networks cannot be reached from nodes in the
    &cloud;. To be able to access external services such as a
    &susemgr; server an &smt; server, or a SAN, you need to make the
    external network(s) known to &cloud;. This is achieved by adding a
    network definition for each external network to
    <filename>/etc/crowbar/network.json</filename>. Refer to
    <xref linkend="app.deploy.network_json"/> for setup instructions.
   </para>
   <example>
    <title>Example Network Definition for the External Network 192.168.150.0/16</title>
<screen>            "external" : {
               "add_bridge" : false,
               "vlan" : <replaceable>XXX</replaceable>,
               "ranges" : {
                  "host" : {
                     "start" : "192.168.150.1",
                     "end" : "192.168.150.254"
                  }
               },
               "broadcast" : "192.168.150.255",
               "netmask" : "255.255.255.0",
               "conduit" : "intf1",
               "subnet" : "192.168.150.0",
               "use_vlan" : true
            }</screen>
   </example>
   <para>
    The value <replaceable>XXX</replaceable> for the VLAN needs to be
    replaced by a value not used within the &cloud; network and not used
    by &o_netw;. By default, the following VLANs are already used:
   </para>
   <table>
    <title>VLANs used by the &cloud; Default Network Setup</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="20*"/>
     <colspec colnum="2" colname="2" colwidth="80*"/>
     <thead>
      <row>
       <entry>
        <para>
         VLAN ID
        </para>
       </entry>
       <entry>
        <para>
         Used by
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         100
        </para>
       </entry>
       <entry>
        <para>
         BMC VLAN (bmc_vlan)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         200
        </para>
       </entry>
       <entry>
        <para>
         Storage Network
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         300
        </para>
       </entry>
       <entry>
        <para>
         Public Network (nova-floating, public)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         400
        </para>
       </entry>
       <entry>
        <para>
         Software-defined network (os_sdn)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         500
        </para>
       </entry>
       <entry>
        <para>
         Private Network (nova-fixed)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         501 - 2500
        </para>
       </entry>
       <entry>
        <para>
         &o_netw; (value of nova-fixed plus 2000)
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.depl.inst.admserv.post.cloud_installation">
  <title>Running the Cloud Installation Script</title>

  <para>
   Before running the cloud installation script to finish the configuration
   of the &admserv; make sure to double-check the following items.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <title>Final Check Points</title>
   <listitem>
    <para>
     Make sure the network configuration is correct. Run <menuchoice>
     <guimenu>&yast;</guimenu> <guimenu>&crow;</guimenu> </menuchoice>
     to review/change the configuration. See
     <xref linkend="sec.depl.adm_inst.crowbar"/> for further instructions.
    </para>
    <important>
     <title>An &haSetup; Requires Teaming Network Mode</title>
     <para>
      In case you are planning to make &cloud; highly available upon the
      initial setup or at a later point in time, make sure to set up the
      network in teaming mode. Such a setup requires at least two network
      cards for each node.
     </para>
    </important>
   </listitem>
   <listitem>
    <para>
     Make sure <command>hostname</command> <option>-f</option> returns a
     fully qualified host name. See
     <xref linkend="sec.depl.adm_inst.network"/> for further instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     Make sure all update and product repositories are available. See
     <xref linkend="sec.depl.adm_conf.repos"/> for further instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     Make sure the operating system and &productname; are up-to-date and
     have the latest patches installed. Run <command>zypper patch</command>
     to install them.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Now everything is in place to finally configure the &admserv;. This is
   done by running the script <filename>install-suse-cloud</filename>. This
   command will install and configure &chef;, and use it to complete the
   installation of &crow; and all required &barcl;s. It will take
   several minutes to complete. If you are <emphasis>not</emphasis> using
   &susemgr; to provide update repositories, run the following command:
  </para>

<screen>screen install-suse-cloud</screen>

  <para>
   In case you are using &susemgr; (as described in
   <xref linkend="sec.depl.adm_conf.repos.scc.remote_susemgr"/>), you need
   to run the following command:
  </para>

<screen>screen env REPOS_SKIP_CHECKS+=" SLES11-SP3-Pool SLES12-Pool" install-suse-cloud</screen>

  <important>
   <title>Use a Terminal Multiplexer to run the Cloud Installation Script</title>
   <para>
    Run the installation script <filename>install-suse-cloud</filename>
    inside of a terminal multiplexer like GNU Screen (provided by the
    <systemitem class="resource">screen</systemitem> package).
   </para>
   <para>
    During the run of this script the network will be reconfigured. This may
    result in interrupting the script when being run from a network
    connection (like SSH). Using <command>screen</command> will continue
    running the script in a session to which you can reconnect via
    <command>screen -r</command> if you lose the connection.
   </para>
  </important>

  <para>
   <command>install-suse-cloud</command> will produce a lot of output that
   gets written to a log file located at
   <filename>/var/log/crowbar/install.log</filename>. Check this log file in
   case something goes wrong. You can run
   <command>install-suse-cloud</command> multiple times as long as you have
   not started to deploy the &ostack; services. It is also possible to
   run <command>install-suse-cloud</command> in verbose mode with the
   <option>-v</option> switch. It will show the same output that goes to the
   log file on STDOUT, too.
  </para>

  <para>
   If the script has successfully finished, you will see a message telling
   you how to log in to the &crow; Web interface.
  </para>
  <warning>
   <title>
    No Network Changes After Having Run the Cloud Installation Script
   </title>
   <para>
    After you have run the cloud installation script, you cannot change the
    network setup anymore. If you did, you would need to completely set up
    the &admserv; again.
   </para>
  </warning> 
  <figure>
   <title>&crow; Web Interface: Initial State</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="depl_node_dashboard_initial.png" width="100%" format="png"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="depl_node_dashboard_initial.png" width="75%" format="png"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
</chapter>
